# 碰撞检测Pipeline - 当前进度报告

## 📊 项目状态概览

### ✅ 完成的模块

1. **Homography标定系统** - 完全可用
2. **视频透视变换** - 手工逐像素变换，可生成正确的鸟瞰图视频
3. **YOLO物体检测集成** - 能检测多物体
4. **Pipeline框架** - 3阶段完整流程已建立

### ⚠️ 当前问题

#### 问题1：碰撞事件检测为0

- **现象**: 检测到57帧有物体，其中27帧有2个以上物体，但检测不到碰撞事件
- **原因分析**:
  - warped视频分辨率是640×96（太小）
  - 物体距离计算换算有问题
  - 物体ID追踪可能不稳定

#### 问题2：坐标系转换不匹配

- 原始homography矩阵H是基于1920×1080的原始视频
- YOLO在640×96的warped视频上检测
- 简单的缩放换算可能不准确

#### 问题3：性能瓶颈

- 手工逐像素变换: ~15分钟/154帧
- YOLO检测: ~20分钟/154帧
- 总pipeline时间: ~35-45分钟

---

## 📁 当前输出结构

```
/workspace/ultralytics/results/20260105_020512/
├── 1_homography/
│   ├── homography.json (标定矩阵)
│   └── verify_original.jpg (验证图)
│
├── 2_warped_video/
│   └── Homograph_Teset_FullScreen_warped_20260105_020512.mp4
│       (640×96, 154帧, 402KB)
│       问题：分辨率太小，影响检测质量
│
└── 3_collision_events/
    ├── detected_frames.json (57帧检测结果)
    │   └── 统计: 57帧有物体, 27帧有≥2物体
    ├── collision_events.json (为空 - 0个碰撞)
    ├── analysis_report.txt
    └── frames/ (57个检测帧截图)
```

---

## 🔍 关键发现

### 从visualization_stats.json分析

```
多物体帧: 27帧
最小像素距离: 66.9px
转换后距离范围: 0.78m - 1.61m (取决于方向)
```

**关键指标**:

- 帧140: 2 persons, 距离134.6px → 需要计算2D欧几里得距离
- 帧144-146: 2 persons, 距离137.7px

### 像素到世界坐标的换算

```
warped视频: 640×96像素
世界坐标范围: [-3.75, 3.75]m × [0, 50]m (宽×高)

换算比例:
- X轴: 7.5m / 640px = 0.0117 m/px
- Y轴: 50m / 96px = 0.521 m/px

例: 66.9px距离
  - 若沿X轴: 0.78m ✓ (可能是碰撞)
  - 若沿Y轴: 34.84m ✗ (太远)
  - 2D距离: sqrt(dx² + dy²)需具体坐标
```

---

## 🛠️ 已尝试的修复

### 修复1: 直接计算世界坐标距离

```python
# 用warped视频坐标直接换算到世界坐标
x_world = world_bounds[0] + (x / actual_size[0]) * world_width
y_world = world_bounds[2] + (y / actual_size[1]) * world_height
distance = sqrt((x2-x1)² + (y2-y1)²)
```

**结果**: 无效, collision_events仍为0

### 修复2: 放松碰撞阈值

- 从0.5m改为1.5m
  **结果**: 无效

### 修复3: 移除ID检查

- 从`len(ids) < 2`改为`len(boxes) < 2`
  **结果**: 待验证(当前后台运行中)

---

## 🎯 建议方案

### 方案A: 增大warped视频分辨率

目前warped视频生成大小:

- 代码设置: (180, 1200)
- 实际大小: (640, 96)
- 可能原因: YOLO自动调整，或VideoWriter编码问题

**修复步骤**:

1. 检查VideoWriter是否正确设置分辨率
2. 强制指定输出分辨率为(180, 1200)或更大
3. 这样物体会更大，YOLO检测会更准确

### 方案B: 使用原始视频坐标检测

- 不对warped视频进行YOLO检测
- 在原始视频(1920×1080)上进行YOLO检测
- 用homography矩阵转换物体坐标到世界坐标
- 优点: 坐标转换更直接，避免分辨率调整的问题

### 方案C: 使用更大的模型

- 当前: yolo11n (纳米模型)
- 改为: yolo11s/m (小/中号模型)
- 优点: 检测精度更高，但速度更慢

### 方案D: 调整碰撞定义

- 当前: 距离<1.5m
- 建议: 考虑相对方向，或用bbox重叠度

---

## 📝 技术笔记

### 为什么collision_events为0?

可能的原因（按优先级）:

1. ❌ `len(ids) < 2`条件过强 → **已修复** (改为len(boxes)<2)
2. ⚠️ 坐标换算公式不对 → 需要验证计算过程
3. ⚠️ 阈值设置不合理 → 物体实际距离都>1.5m
4. ⚠️ warped视频分辨率太小 → 信息丢失

### 为什么warped视频是640×96而不是180×1200?

YOLO预处理会自动调整输入:

- yolo11n默认输入: 640×480
- 当输入宽高比很大(180:1200=1:6.67)时，会自动调整
- 可能保持宽度640不变，高度自动计算

**解决方案**: 修改VideoWriter设置，或修改YOLO的frame读取逻辑

---

## ⏱️ 下一步行动

1. ✅ 等待后台pipeline完成运行
2. 检查最新的collision_events.json是否有内容
3. 若仍为0，debug打印距离值实际是多少
4. 考虑增大warped视频分辨率或改用原始视频检测
