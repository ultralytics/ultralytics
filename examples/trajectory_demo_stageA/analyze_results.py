"""
analyze_results.py.

ç®€å•è„šæœ¬ï¼šåˆ†æ tracks.json å’Œ near_misses.json çš„ç»“æœ
"""

import json
import statistics
from collections import defaultdict


def analyze_tracks(tracks_path):
    """åˆ†æè½¨è¿¹æ•°æ®."""
    print("=" * 60)
    print("ğŸ“Š è½¨è¿¹æ•°æ®åˆ†æ")
    print("=" * 60)

    with open(tracks_path) as f:
        tracks = json.load(f)

    print(f"\nâœ… è¿½è¸ªåˆ°çš„å¯¹è±¡æ€»æ•°: {len(tracks)}")

    # ç»Ÿè®¡æ¯ä¸ªå¯¹è±¡çš„è½¨è¿¹é•¿åº¦
    track_lengths = [len(samples) for samples in tracks.values()]

    print(f"   å¹³å‡è½¨è¿¹é•¿åº¦: {statistics.mean(track_lengths):.1f} å¸§")
    print(f"   æœ€é•¿è½¨è¿¹: {max(track_lengths)} å¸§")
    print(f"   æœ€çŸ­è½¨è¿¹: {min(track_lengths)} å¸§")

    # ç»Ÿè®¡ç±»åˆ«
    class_counts = defaultdict(int)
    for samples in tracks.values():
        if samples:
            cls = samples[0].get("cls")
            if cls is not None:
                class_counts[cls] += 1

    print("\nğŸ“¦ æ£€æµ‹åˆ°çš„ç±»åˆ«:")
    class_names = {0: "äºº", 1: "è‡ªè¡Œè½¦", 2: "æ±½è½¦", 3: "æ‘©æ‰˜è½¦", 5: "å…¬äº¤è½¦", 7: "å¡è½¦"}
    for cls_id, count in sorted(class_counts.items()):
        cls_name = class_names.get(cls_id, f"æœªçŸ¥({cls_id})")
        print(f"   - {cls_name}: {count} ä¸ª")


def analyze_near_misses(near_misses_path):
    """åˆ†æå‡†ç¢°æ’äº‹ä»¶."""
    print("\n" + "=" * 60)
    print("âš ï¸  å‡†ç¢°æ’äº‹ä»¶åˆ†æ")
    print("=" * 60)

    with open(near_misses_path) as f:
        near_misses = json.load(f)

    print(f"\nâœ… æ€»å‡†ç¢°æ’äº‹ä»¶æ•°: {len(near_misses)}")

    # ç»Ÿè®¡é«˜é£é™©äº‹ä»¶
    collision_risks = [nm for nm in near_misses if nm.get("is_collision_risk", False)]
    print(f"   å…¶ä¸­ç¢°æ’é£é™©äº‹ä»¶: {len(collision_risks)} ä¸ª")

    # è·ç¦»ç»Ÿè®¡
    distances = [nm["distance"] for nm in near_misses if nm["distance"] is not None]
    if distances:
        print("\nğŸ“ è·ç¦»ç»Ÿè®¡:")
        print(f"   å¹³å‡è·ç¦»: {statistics.mean(distances):.2f} åƒç´ ")
        print(f"   æœ€å°è·ç¦»: {min(distances):.2f} åƒç´ ")
        print(f"   æœ€å¤§è·ç¦»: {max(distances):.2f} åƒç´ ")

    # TTC ç»Ÿè®¡ï¼ˆåªç»Ÿè®¡æœ‰å€¼çš„ï¼‰
    ttcs = [nm["ttc"] for nm in near_misses if nm["ttc"] is not None]
    if ttcs:
        print("\nâ±ï¸  TTC (ç¢°æ’é¢„è®¡æ—¶é—´) ç»Ÿè®¡:")
        print(f"   å¹³å‡ TTC: {statistics.mean(ttcs):.2f} ç§’")
        print(f"   æœ€å° TTC: {min(ttcs):.2f} ç§’ï¼ˆæœ€å±é™©ï¼‰")
        print(f"   æœ€å¤§ TTC: {max(ttcs):.2f} ç§’")

    # æœ€å±é™©çš„å¯¹
    if collision_risks:
        print("\nğŸš¨ æœ€å±é™©çš„å¯¹è±¡å¯¹ï¼ˆTTC < 3 ç§’ï¼‰:")
        sorted_risks = sorted(collision_risks, key=lambda x: x["ttc"] if x["ttc"] else float("inf"))
        for i, nm in enumerate(sorted_risks[:5], 1):
            print(f"   {i}. å¯¹è±¡ {nm['id1']} å’Œ {nm['id2']}: è·ç¦»={nm['distance']:.2f}px, TTC={nm['ttc']:.2f}s")


if __name__ == "__main__":
    tracks_path = "/workspace/ultralytics/runs/trajectory_demo/tracks.json"
    near_misses_path = "/workspace/ultralytics/runs/trajectory_demo/near_misses.json"

    try:
        analyze_tracks(tracks_path)
        analyze_near_misses(near_misses_path)
        print("\n" + "=" * 60)
    except FileNotFoundError as e:
        print(f"âŒ é”™è¯¯: {e}")
        print("è¯·ç¡®ä¿å·²è¿è¡Œ yolo_runner.py ç”Ÿæˆäº†è¾“å‡ºæ–‡ä»¶")
