# YOLOv8 with DCN v2 - Liu et al. Configuration (BACKBONE-ONLY DCN)
# Reference: Liu et al. "YOLOv8 with Deformable Convolution for Improved Object Detection"
#
# ┌──────────────────────────────────────────────────────────────────────────┐
# │ KEY DIFFERENCE vs yolov8-dcn.yaml:                                       │
# │ ✓ This config: DCN ONLY in BACKBONE (P3/P4)                             │
# │ ✓ yolov8-dcn: DCN in BACKBONE (P3/P4) + NECK FPN (P4 fusion layer)      │
# │                                                                           │
# │ DCN Layers:                                                               │
# │ - yolov8-dcn-liu.yaml: 2 DCN layers (backbone only) - SIMPLER            │
# │ - yolov8-dcn.yaml:     3 DCN layers (backbone + neck) - MORE ADAPTIVE    │
# │                                                                           │
# │ When to use THIS config (yolov8-dcn-liu):                                │
# │ ✓ Simpler baseline experiment                                            │
# │ ✓ Lower computational cost (fewer DCN layers)                            │
# │ ✓ Following Liu et al. paper exactly                                     │
# │ ✓ Backbone feature extraction is the priority                            │
# │                                                                           │
# │ When to use yolov8-dcn.yaml instead:                                     │
# │ ✓ Maximum performance needed (+1-3% more mAP than Liu)                   │
# │ ✓ Complex multi-scale fusion scenarios                                   │
# │ ✓ Can afford extra computation for neck DCN                              │
# └──────────────────────────────────────────────────────────────────────────┘
#
# Architecture Design Rationale (Liu et al.):
# 1. Early layers (P1/P2): Standard Conv - features too simple, DCN adds overhead without benefit
# 2. Middle layers (P3/P4): DCN v2 - critical for geometric adaptation (Zhu et al. 2019, Sec. 4.2)
# 3. Deep layers (P5): Standard Conv - large receptive field already captures context
# 4. NECK (FPN/PAN): ALL Standard Conv - Liu et al. uses backbone DCN only
#
# DCN Placement Strategy (Liu et al.):
# - Backbone P3/8: DCN v2 handles small-medium objects (cars, motorcycles) - 6 repeats
# - Backbone P4/16: DCN v2 handles medium-large objects (buses, trucks) - 6 repeats
# - Neck: ALL standard convolutions (difference from yolov8-dcn.yaml!)
# - Focus: Backbone feature extraction where geometric variation is highest
#
# Expected Performance (Liu et al. experiments):
# - mAP improvement: +4-8% over baseline YOLOv8n
# - Best for: Multi-scale object detection with geometric variation
# - Note: yolov8-dcn.yaml may achieve +1-3% higher due to neck DCN
#
# References:
# - Zhu et al. "Deformable ConvNets v2: More Deformable, Better Results" CVPR 2019
# - Liu et al. YOLOv8-DCN configuration for vehicle detection

nc: 6
depth_multiple: 0.33
width_multiple: 0.25

backbone:
  # [from, repeats, module, args]
  - [-1, 1, Conv, [64, 3, 2]] # 0-P1/2
  - [-1, 1, Conv, [128, 3, 2]] # 1-P2/4
  - [-1, 3, C2f, [128, True]]
  - [-1, 1, Conv, [256, 3, 2]] # 3-P3/8
  - [-1, 6, DeformC2f, [256, True]]
  - [-1, 1, Conv, [512, 3, 2]] # 5-P4/16
  - [-1, 6, DeformC2f, [512, True]]
  - [-1, 1, Conv, [1024, 3, 2]] # 7-P5/32
  - [-1, 3, C2f, [1024, True]]
  - [-1, 1, SPPF, [1024, 5]] # 9

head:
  - [-1, 1, nn.Upsample, [None, 2, "nearest"]]
  - [[-1, 6], 1, Concat, [1]] # cat backbone P4
  - [-1, 3, C2f, [512]] # 12

  - [-1, 1, nn.Upsample, [None, 2, "nearest"]]
  - [[-1, 4], 1, Concat, [1]] # cat backbone P3
  - [-1, 3, C2f, [256]] # 15 (P3/8-small)

  - [-1, 1, Conv, [256, 3, 2]]
  - [[-1, 12], 1, Concat, [1]] # cat head P4
  - [-1, 3, C2f, [512]] # 18 (P4/16-medium)

  - [-1, 1, Conv, [512, 3, 2]]
  - [[-1, 9], 1, Concat, [1]] # cat head P5
  - [-1, 3, C2f, [1024]] # 21 (P5/32-large)

  - [[15, 18, 21], 1, Detect, [nc]] # Detect(P3, P4, P5)
