{
  "YOLO12": {
    "author": "Yunjie Tian, Qixiang Ye, and David Doermann",
    "org": "University at Buffalo and University of Chinese Academy of Sciences",
    "short_description": "YOLO12 introduces an attention-centric architecture that departs from the traditional CNN-based approaches used in previous YOLO models, yet retains the real-time inference speed essential for many applications.",
    "date": "2025-02-18",
    "arxiv": "https://arxiv.org/abs/2502.12524",
    "github": "https://github.com/sunsmarterjie/yolov12",
    "docs": "https://docs.ultralytics.com/models/yolo12/",
    "official": false,
    "latest": false,
    "show_graph": false,
    "graph_color_override": "#1f77b4",
    "show_card": false,
    "tasks": ["Detect", "Segment", "Classify"],
    "performance": {
      "n": {
        "size": 640,
        "map": 40.6,
        "cpu": "",
        "t4": 1.64,
        "params": 2.6,
        "flops": 6.5,
        "file_size": 5.34,
        "model_full_name": "YOLO12n"
      },
      "s": {
        "size": 640,
        "map": 48.0,
        "cpu": "",
        "t4": 2.61,
        "params": 9.3,
        "flops": 21.4,
        "file_size": 18.1,
        "model_full_name": "YOLO12s"
      },
      "m": {
        "size": 640,
        "map": 52.5,
        "cpu": "",
        "t4": 4.86,
        "params": 20.2,
        "flops": 67.5,
        "file_size": 39,
        "model_full_name": "YOLO12m"
      },
      "l": {
        "size": 640,
        "map": 53.7,
        "cpu": "",
        "t4": 6.77,
        "params": 26.4,
        "flops": 88.9,
        "file_size": 51.2,
        "model_full_name": "YOLO12l"
      },
      "x": {
        "size": 640,
        "map": 55.2,
        "cpu": "",
        "t4": 11.79,
        "params": 59.1,
        "flops": 199.0,
        "file_size": 114,
        "model_full_name": "YOLO12x"
      }
    }
  },
  "Ultralytics YOLO11": {
    "author": "Glenn Jocher and Jing Qiu",
    "org": "Ultralytics",
    "short_description": "Ultralytics YOLO11 is the latest iteration in the Ultralytics YOLO series of real-time object detectors, redefining what's possible with cutting-edge accuracy, speed, and efficiency.",
    "date": "2024-09-27",
    "arxiv": "",
    "github": "https://github.com/ultralytics/ultralytics",
    "docs": "https://docs.ultralytics.com/models/yolo11/",
    "official": true,
    "latest": true,
    "show_graph": true,
    "weightBase": "yolo11",
    "graph_color_override": "#0b23a9",
    "show_card": true,
    "tasks": ["Detect", "Segment", "Classify", "Pose", "OBB"],
    "performance": {
      "n": {
        "size": 640,
        "map": 39.5,
        "cpu": 56.1,
        "t4": 1.5,
        "params": 2.6,
        "flops": 6.5,
        "file_size": 5.35,
        "model_full_name": "YOLO11n"
      },
      "s": {
        "size": 640,
        "map": 47.0,
        "cpu": 90.0,
        "t4": 2.5,
        "params": 9.4,
        "flops": 21.5,
        "file_size": 18.4,
        "model_full_name": "YOLO11s"
      },
      "m": {
        "size": 640,
        "map": 51.5,
        "cpu": 183.2,
        "t4": 4.7,
        "params": 20.1,
        "flops": 68.0,
        "file_size": 38.8,
        "model_full_name": "YOLO11m"
      },
      "l": {
        "size": 640,
        "map": 53.4,
        "cpu": 238.6,
        "t4": 6.2,
        "params": 25.3,
        "flops": 86.9,
        "file_size": 49,
        "model_full_name": "YOLO11l"
      },
      "x": {
        "size": 640,
        "map": 54.7,
        "cpu": 462.8,
        "t4": 11.3,
        "params": 56.9,
        "flops": 194.9,
        "file_size": 109,
        "model_full_name": "YOLO11x"
      }
    }
  },
  "YOLOv10": {
    "author": "Ao Wang, Hui Chen, Lihao Liu, et al.",
    "org": "Tsinghua University",
    "short_description": "YOLOv10, built on the Ultralytics Python package by researchers at Tsinghua University, introduces a new approach to real-time object detection, addressing both the post-processing and model architecture deficiencies found in previous YOLO versions.",
    "date": "2024-05-23",
    "arxiv": "https://arxiv.org/abs/2405.14458",
    "github": "https://github.com/THU-MIG/yolov10",
    "docs": "https://docs.ultralytics.com/models/yolov10/",
    "official": false,
    "latest": false,
    "show_graph": true,
    "graph_color_override": "#ff7f0e",
    "show_card": true,
    "tasks": ["Detect"],
    "performance": {
      "n": {
        "size": 640,
        "map": 39.5,
        "cpu": "",
        "t4": 1.56,
        "params": 2.3,
        "flops": 6.7,
        "file_size": 5.59,
        "model_full_name": "YOLOv10n"
      },
      "s": {
        "size": 640,
        "map": 46.7,
        "cpu": "",
        "t4": 2.66,
        "params": 7.2,
        "flops": 21.6,
        "file_size": 15.9,
        "model_full_name": "YOLOv10s"
      },
      "m": {
        "size": 640,
        "map": 51.3,
        "cpu": "",
        "t4": 5.48,
        "params": 15.4,
        "flops": 59.1,
        "file_size": 32.1,
        "model_full_name": "YOLOv10m"
      },
      "b": {
        "size": 640,
        "map": 52.7,
        "cpu": "",
        "t4": 6.54,
        "params": 24.4,
        "flops": 92.0,
        "file_size": 39.7,
        "model_full_name": "YOLOv10b"
      },
      "l": {
        "size": 640,
        "map": 53.3,
        "cpu": "",
        "t4": 8.33,
        "params": 29.5,
        "flops": 120.3,
        "file_size": 50,
        "model_full_name": "YOLOv10l"
      },
      "x": {
        "size": 640,
        "map": 54.4,
        "cpu": "",
        "t4": 12.2,
        "params": 56.9,
        "flops": 160.4,
        "file_size": 61.4,
        "model_full_name": "YOLOv10x"
      }
    }
  },
  "YOLOv9": {
    "author": "Chien-Yao Wang and Hong-Yuan Mark Liao",
    "org": "Institute of Information Science, Academia Sinica, Taiwan",
    "short_description": "YOLOv9 marks a significant advancement in real-time object detection, introducing groundbreaking techniques such as Programmable Gradient Information (PGI) and the Generalized Efficient Layer Aggregation Network (GELAN).",
    "date": "2024-02-21",
    "arxiv": "https://arxiv.org/abs/2402.13616",
    "github": "https://github.com/WongKinYiu/yolov9",
    "docs": "https://docs.ultralytics.com/models/yolov9/",
    "official": false,
    "latest": false,
    "show_graph": true,
    "graph_color_override": "#2ca02c",
    "show_card": true,
    "tasks": ["Detect", "Segment"],
    "performance": {
      "t": {
        "size": 640,
        "map": 38.3,
        "cpu": "",
        "t4": 2.3,
        "params": 2.0,
        "flops": 7.7,
        "file_size": 4.74,
        "model_full_name": "YOLOv9t"
      },
      "s": {
        "size": 640,
        "map": 46.8,
        "cpu": "",
        "t4": 3.54,
        "params": 7.1,
        "flops": 26.4,
        "file_size": 14.7,
        "model_full_name": "YOLOv9s"
      },
      "m": {
        "size": 640,
        "map": 51.4,
        "cpu": "",
        "t4": 6.43,
        "params": 20.0,
        "flops": 76.3,
        "file_size": 39.1,
        "model_full_name": "YOLOv9m"
      },
      "c": {
        "size": 640,
        "map": 53.0,
        "cpu": "",
        "t4": 7.16,
        "params": 25.3,
        "flops": 102.1,
        "file_size": 49.4,
        "model_full_name": "YOLOv9c"
      },
      "e": {
        "size": 640,
        "map": 55.6,
        "cpu": "",
        "t4": 16.77,
        "params": 57.3,
        "flops": 189.0,
        "file_size": 112,
        "model_full_name": "YOLOv9e"
      }
    }
  },
  "Ultralytics YOLOv8": {
    "author": "Glenn Jocher, Ayush Chaurasia, and Jing Qiu",
    "org": "Ultralytics",
    "short_description": "Ultralytics YOLOv8 was released by Ultralytics on January 10th, 2023, offering cutting-edge performance in terms of accuracy and speed.",
    "date": "2023-01-10",
    "arxiv": "",
    "github": "https://github.com/ultralytics/ultralytics",
    "docs": "https://docs.ultralytics.com/models/yolov8/",
    "official": true,
    "latest": false,
    "show_graph": true,
    "weightBase": "yolov8",
    "graph_color_override": "#d62728",
    "show_card": true,
    "tasks": ["Detect", "Segment", "Classify", "Pose", "OBB"],
    "performance": {
      "n": {
        "size": 640,
        "map": 37.3,
        "cpu": 80.4,
        "t4": 1.47,
        "params": 3.2,
        "flops": 8.7,
        "file_size": 6.25,
        "model_full_name": "YOLOv8n"
      },
      "s": {
        "size": 640,
        "map": 44.9,
        "cpu": 128.4,
        "t4": 2.66,
        "params": 11.2,
        "flops": 28.6,
        "file_size": 21.5,
        "model_full_name": "YOLOv8s"
      },
      "m": {
        "size": 640,
        "map": 50.2,
        "cpu": 234.7,
        "t4": 5.86,
        "params": 25.9,
        "flops": 78.9,
        "file_size": 49.7,
        "model_full_name": "YOLOv8m"
      },
      "l": {
        "size": 640,
        "map": 52.9,
        "cpu": 375.2,
        "t4": 9.06,
        "params": 43.7,
        "flops": 165.2,
        "file_size": 83.7,
        "model_full_name": "YOLOv8l"
      },
      "x": {
        "size": 640,
        "map": 53.9,
        "cpu": 479.1,
        "t4": 14.37,
        "params": 68.2,
        "flops": 257.8,
        "file_size": 131,
        "model_full_name": "YOLOv8x"
      }
    }
  },
  "YOLOv7": {
    "author": "Chien-Yao Wang, Alexey Bochkovskiy, and Hong-Yuan Mark Liao",
    "org": "Institute of Information Science, Academia Sinica, Taiwan",
    "short_description": "YOLOv7 is a state-of-the-art real-time object detector that surpasses all known object detectors in both speed and accuracy in the range from 5 FPS to 160 FPS.",
    "date": "2022-07-06",
    "arxiv": "https://arxiv.org/abs/2207.02696",
    "github": "https://github.com/WongKinYiu/yolov7",
    "docs": "https://docs.ultralytics.com/models/yolov7/",
    "official": false,
    "latest": false,
    "show_graph": true,
    "graph_color_override": "#9467bd",
    "show_card": true,
    "tasks": ["Detect"],
    "performance": {
      "l": {
        "size": 640,
        "map": 51.4,
        "cpu": "",
        "t4": 6.84,
        "params": 36.9,
        "flops": 104.7,
        "file_size": "",
        "model_full_name": "YOLOv7l"
      },
      "x": {
        "size": 640,
        "map": 53.1,
        "cpu": "",
        "t4": 11.57,
        "params": 71.3,
        "flops": 189.9,
        "file_size": "",
        "model_full_name": "YOLOv7x"
      }
    }
  },
  "YOLOv6-3.0": {
    "author": "Chuyi Li, Lulu Li, Yifei Geng, Hongliang Jiang, Meng Cheng, Bo Zhang, Zaidan Ke, Xiaoming Xu, and Xiangxiang Chu",
    "org": "Meituan",
    "short_description": "Meituan YOLOv6 is a cutting-edge object detector that offers remarkable balance between speed and accuracy, making it a popular choice for real-time applications.",
    "date": "2023-01-13",
    "arxiv": "https://arxiv.org/abs/2301.05586",
    "github": "https://github.com/meituan/YOLOv6",
    "docs": "https://docs.ultralytics.com/models/yolov6/",
    "official": false,
    "latest": false,
    "show_graph": true,
    "graph_color_override": "#8c564b",
    "show_card": true,
    "weightBase": "yolov6",
    "tasks": ["Detect"],
    "performance": {
      "n": {
        "size": 640,
        "map": 37.5,
        "cpu": "",
        "t4": 1.17,
        "params": 4.7,
        "flops": 11.4,
        "file_size": "",
        "model_full_name": "YOLOv6-N"
      },
      "s": {
        "size": 640,
        "map": 45.0,
        "cpu": "",
        "t4": 2.66,
        "params": 18.5,
        "flops": 45.3,
        "file_size": "",
        "model_full_name": "YOLOv6-S"
      },
      "m": {
        "size": 640,
        "map": 50.0,
        "cpu": "",
        "t4": 5.28,
        "params": 34.9,
        "flops": 85.8,
        "file_size": "",
        "model_full_name": "YOLOv6-M"
      },
      "l": {
        "size": 640,
        "map": 52.8,
        "cpu": "",
        "t4": 8.95,
        "params": 59.6,
        "flops": 150.7,
        "file_size": "",
        "model_full_name": "YOLOv6-L"
      }
    }
  },
  "Ultralytics YOLOv5": {
    "author": "Glenn Jocher",
    "org": "Ultralytics",
    "short_description": "Ultralytics YOLOv5u represents an advancement in object detection methodologies. Originating from the foundational architecture of the YOLOv5 model developed by Ultralytics, Ultralytics YOLOv5u integrates the anchor-free, objectness-free split head, a feature previously introduced in the YOLOv8 models.",
    "date": "2020-06-26",
    "arxiv": "",
    "github": "https://github.com/ultralytics/yolov5",
    "docs": "https://docs.ultralytics.com/models/yolov5/",
    "official": true,
    "latest": false,
    "show_graph": true,
    "graph_color_override": "#e377c2",
    "weightBase": "yolov5",
    "show_card": true,
    "tasks": ["Detect", "Segment"],
    "performance": {
      "n": {
        "size": 640,
        "map": 28.0,
        "cpu": 73.6,
        "t4": 1.12,
        "params": 2.6,
        "flops": 7.7,
        "file_size": 5.31,
        "model_full_name": "YOLOv5n"
      },
      "s": {
        "size": 640,
        "map": 37.4,
        "cpu": 120.7,
        "t4": 1.92,
        "params": 9.1,
        "flops": 24.0,
        "file_size": 17.7,
        "model_full_name": "YOLOv5s"
      },
      "m": {
        "size": 640,
        "map": 45.4,
        "cpu": 233.9,
        "t4": 4.03,
        "params": 25.1,
        "flops": 64.2,
        "file_size": 48.2,
        "model_full_name": "YOLOv5m"
      },
      "l": {
        "size": 640,
        "map": 49.0,
        "cpu": 408.4,
        "t4": 6.61,
        "params": 53.2,
        "flops": 135.0,
        "file_size": 102,
        "model_full_name": "YOLOv5l"
      },
      "x": {
        "size": 640,
        "map": 50.7,
        "cpu": 763.2,
        "t4": 11.89,
        "params": 97.2,
        "flops": 246.4,
        "file_size": 186,
        "model_full_name": "YOLOv5x"
      }
    }
  },
  "PP-YOLOE+": {
    "author": "PaddlePaddle Authors",
    "org": "Baidu",
    "short_description": "PP-YOLOE is an excellent single-stage anchor-free model based on PP-YOLOv2, surpassing a variety of popular YOLO models. PP-YOLOE has a series of models, named s/m/l/x, which are configured through width multiplier and depth multiplier.",
    "date": "2022-04-02",
    "arxiv": "https://arxiv.org/abs/2203.16250",
    "github": "https://github.com/PaddlePaddle/PaddleDetection/",
    "docs": "https://github.com/PaddlePaddle/PaddleDetection/blob/release/2.8.1/configs/ppyoloe/README.md",
    "official": false,
    "latest": false,
    "show_graph": true,
    "graph_color_override": "#7f7f7f",
    "show_card": false,
    "tasks": ["Detect", "Segment"],
    "performance": {
      "t": {
        "size": 640,
        "map": 39.9,
        "cpu": "",
        "t4": 2.84,
        "params": 4.85,
        "flops": 19.15,
        "file_size": "",
        "model_full_name": "PP-YOLOE+t"
      },
      "s": {
        "size": 640,
        "map": 43.7,
        "cpu": "",
        "t4": 2.62,
        "params": 7.93,
        "flops": 17.36,
        "file_size": "",
        "model_full_name": "PP-YOLOE+s"
      },
      "m": {
        "size": 640,
        "map": 49.8,
        "cpu": "",
        "t4": 5.56,
        "params": 23.43,
        "flops": 49.91,
        "file_size": "",
        "model_full_name": "PP-YOLOE+m"
      },
      "l": {
        "size": 640,
        "map": 52.9,
        "cpu": "",
        "t4": 8.36,
        "params": 52.2,
        "flops": 110.07,
        "file_size": "",
        "model_full_name": "PP-YOLOE+l"
      },
      "x": {
        "size": 640,
        "map": 54.7,
        "cpu": "",
        "t4": 14.3,
        "params": 98.42,
        "flops": 206.59,
        "file_size": "",
        "model_full_name": "PP-YOLOE+x"
      }
    }
  },

  "DAMO-YOLO": {
    "author": "Xianzhe Xu, Yiqi Jiang, Weihua Chen, Yilun Huang, Yuan Zhang, and Xiuyu Sun",
    "org": "Alibaba Group",
    "date": "2022-11-23",
    "arxiv": "https://arxiv.org/abs/2211.15444v2",
    "github": "https://github.com/tinyvision/DAMO-YOLO",
    "docs": "https://github.com/tinyvision/DAMO-YOLO/blob/master/README.md",
    "official": false,
    "latest": false,
    "show_graph": true,
    "graph_color_override": "#bcbd22",
    "show_card": false,
    "tasks": ["Detect"],
    "performance": {
      "t": {
        "size": 640,
        "map": 42.0,
        "cpu": "",
        "t4": 2.32,
        "params": 8.5,
        "flops": 18.1,
        "file_size": "",
        "model_full_name": "DAMO-YOLO-T"
      },
      "s": {
        "size": 640,
        "map": 46.0,
        "cpu": "",
        "t4": 3.45,
        "params": 16.3,
        "flops": 37.8,
        "file_size": "",
        "model_full_name": "DAMO-YOLO-S"
      },
      "m": {
        "size": 640,
        "map": 49.2,
        "cpu": "",
        "t4": 5.09,
        "params": 28.2,
        "flops": 61.8,
        "file_size": "",
        "model_full_name": "DAMO-YOLO-M"
      },
      "l": {
        "size": 640,
        "map": 50.8,
        "cpu": "",
        "t4": 7.18,
        "params": 42.1,
        "flops": 97.3,
        "file_size": "",
        "model_full_name": "DAMO-YOLO-L"
      }
    }
  },
  "YOLOX": {
    "author": "Zheng Ge, Songtao Liu, Feng Wang, Zeming Li, and Jian Sun",
    "org": "Megvii",
    "short_description": "YOLOX is an anchor-free version of YOLO, with a simpler design but better performance! It aims to bridge the gap between research and industrial communities.",
    "date": "2021-07-18",
    "arxiv": "https://arxiv.org/abs/2107.08430",
    "github": "https://github.com/Megvii-BaseDetection/YOLOX",
    "docs": "https://yolox.readthedocs.io/en/latest/",
    "official": false,
    "latest": false,
    "show_graph": true,
    "graph_color_override": "#17becf",
    "show_card": false,
    "tasks": ["Detect"],
    "performance": {
      "nano": {
        "size": 416,
        "map": 25.8,
        "cpu": "",
        "t4": "",
        "params": 0.91,
        "flops": 1.08,
        "file_size": "",
        "model_full_name": "YOLOX-Nano"
      },
      "tiny": {
        "size": 416,
        "map": 32.8,
        "cpu": "",
        "t4": "",
        "params": 5.06,
        "flops": 6.45,
        "file_size": "",
        "model_full_name": "YOLOX-Tiny"
      },
      "s": {
        "size": 640,
        "map": 40.5,
        "cpu": "",
        "t4": 2.56,
        "params": 9.0,
        "flops": 26.8,
        "file_size": "",
        "model_full_name": "YOLOX-s"
      },
      "m": {
        "size": 640,
        "map": 46.9,
        "cpu": "",
        "t4": 5.43,
        "params": 25.3,
        "flops": 73.8,
        "file_size": "",
        "model_full_name": "YOLOX-m"
      },
      "l": {
        "size": 640,
        "map": 49.7,
        "cpu": "",
        "t4": 9.04,
        "params": 54.2,
        "flops": 155.6,
        "file_size": "",
        "model_full_name": "YOLOX-l"
      },
      "x": {
        "size": 640,
        "map": 51.1,
        "cpu": "",
        "t4": 16.1,
        "params": 99.1,
        "flops": 281.9,
        "file_size": "",
        "model_full_name": "YOLOX-x"
      }
    }
  },
  "RTDETRv2": {
    "author": "Wenyu Lv, Yian Zhao, Qinyao Chang, Kui Huang, Guanzhong Wang, and Yi Liu",
    "org": "Baidu",
    "short_description": "RT-DETRv2, an improved Real-Time DEtection TRansformer (RT-DETR). RT-DETRv2 builds upon the previous state-of-the-art real-time detector, RT-DETR, and opens up a set of bag of freebies for flexibility and practicality, as well as optimizing the training strategy to achieve enhanced performance.",
    "date": "2023-04-17",
    "arxiv": "https://arxiv.org/abs/2304.08069",
    "github": "https://github.com/lyuwenyu/RT-DETR/tree/main/rtdetrv2_pytorch",
    "docs": "https://github.com/lyuwenyu/RT-DETR/tree/main/rtdetrv2_pytorch#readme",
    "official": false,
    "latest": false,
    "show_graph": true,
    "graph_color_override": "#eccd22",
    "show_card": false,
    "tasks": ["Detect"],
    "performance": {
      "s": {
        "size": 640,
        "map": 48.1,
        "cpu": "",
        "t4": 5.03,
        "params": 20,
        "flops": 60,
        "file_size": "",
        "model_full_name": "RTDETRv2-S"
      },
      "m": {
        "size": 640,
        "map": 51.9,
        "cpu": "",
        "t4": 7.51,
        "params": 36,
        "flops": 100,
        "file_size": "",
        "model_full_name": "RTDETRv2-M"
      },
      "l": {
        "size": 640,
        "map": 53.4,
        "cpu": "",
        "t4": 9.76,
        "params": 42,
        "flops": 136,
        "file_size": 63.4,
        "model_full_name": "RTDETRv2-L"
      },
      "x": {
        "size": 640,
        "map": 54.3,
        "cpu": "",
        "t4": 15.03,
        "params": 76,
        "flops": 259,
        "file_size": 129,
        "model_full_name": "RTDETRv2-X"
      }
    }
  },
  "EfficientDet": {
    "author": "Mingxing Tan, Ruoming Pang, and Quoc V. Le",
    "org": "Google",
    "date": "2019-11-20",
    "short_description": "EfficientDet is a family of object detectors that improves efficiency through a weighted BiFPN for fast multi-scale feature fusion and a compound scaling method for uniformly scaling resolution, depth, and width. It achieves state of the art accuracy on COCO while being significantly smaller and faster than previous detectors.",
    "arxiv": "https://arxiv.org/abs/1911.09070",
    "github": "https://github.com/google/automl/tree/master/efficientdet",
    "docs": "https://github.com/google/automl/tree/master/efficientdet#readme",
    "official": false,
    "latest": false,
    "show_graph": true,
    "graph_color_override": "#000000",
    "show_card": false,
    "tasks": ["Detect"],
    "performance": {
      "d0": {
        "size": 640,
        "map": 34.6,
        "cpu": 10.2,
        "t4": 3.92,
        "params": 3.9,
        "flops": 2.54,
        "file_size": "",
        "model_full_name": "EfficientDet-D0"
      },
      "d1": {
        "size": 640,
        "map": 40.5,
        "cpu": 13.5,
        "t4": 7.31,
        "params": 6.6,
        "flops": 6.1,
        "file_size": "",
        "model_full_name": "EfficientDet-D1"
      },
      "d2": {
        "size": 640,
        "map": 43.0,
        "cpu": 17.7,
        "t4": 10.92,
        "params": 8.1,
        "flops": 11.0,
        "file_size": "",
        "model_full_name": "EfficientDet-D2"
      },
      "d3": {
        "size": 640,
        "map": 47.5,
        "cpu": 28.0,
        "t4": 19.59,
        "params": 12.0,
        "flops": 24.9,
        "file_size": "",
        "model_full_name": "EfficientDet-D3"
      },
      "d4": {
        "size": 640,
        "map": 49.7,
        "cpu": 42.8,
        "t4": 33.55,
        "params": 20.7,
        "flops": 55.2,
        "file_size": "",
        "model_full_name": "EfficientDet-D4"
      },
      "d5": {
        "size": 640,
        "map": 51.5,
        "cpu": 72.5,
        "t4": 67.86,
        "params": 33.7,
        "flops": 130.0,
        "file_size": "",
        "model_full_name": "EfficientDet-D5"
      },
      "d6": {
        "size": 640,
        "map": 52.6,
        "cpu": 92.8,
        "t4": 89.29,
        "params": 51.9,
        "flops": 226.0,
        "file_size": "",
        "model_full_name": "EfficientDet-D6"
      },
      "d7": {
        "size": 640,
        "map": 53.7,
        "cpu": 122.0,
        "t4": 128.07,
        "params": 51.9,
        "flops": 325.0,
        "file_size": "",
        "model_full_name": "EfficientDet-D7"
      }
    }
  },
  "Gold-YOLO": {
    "author": "Cheng Wang, Wei He, Ying Nie, Jianyuan Guo, Chuanjian Liu, Yunhe Wang, and Kai Han",
    "org": "Huawei Noah's Ark Lab",
    "date": "2023-09-20",
    "short_description": "Gold-YOLO is an efficient object detector introducing a Gather-and-Distribute (GD) mechanism with convolution and self-attention to enhance multi-scale feature fusion, achieving a strong balance between speed and accuracy.",
    "arxiv": "https://arxiv.org/abs/2309.11331",
    "github": "https://github.com/huawei-noah/Efficient-Computing/tree/master/Detection/Gold-YOLO",
    "docs": "https://github.com/huawei-noah/Efficient-Computing/blob/master/Detection/Gold-YOLO/README.md",
    "official": false,
    "latest": false,
    "show_graph": false,
    "show_card": false,
    "tasks": ["Detect"],
    "performance": {
      "n": {
        "size": 640,
        "map": 39.9,
        "cpu": "",
        "t4": 1.66,
        "params": 5.6,
        "flops": 12.1,
        "file_size": "",
        "model_full_name": "Gold-YOLO-N"
      },
      "s": {
        "size": 640,
        "map": 46.4,
        "cpu": "",
        "t4": 3.43,
        "params": 21.5,
        "flops": 46.0,
        "file_size": "",
        "model_full_name": "Gold-YOLO-S"
      },
      "m": {
        "size": 640,
        "map": 51.1,
        "cpu": "",
        "t4": 6.43,
        "params": 41.3,
        "flops": 87.5,
        "file_size": "",
        "model_full_name": "Gold-YOLO-M"
      },
      "l": {
        "size": 640,
        "map": 53.3,
        "cpu": "",
        "t4": 10.64,
        "params": 75.1,
        "flops": 151.7,
        "file_size": "",
        "model_full_name": "Gold-YOLO-L"
      }
    }
  },
  "D-FINE": {
    "author": "Yansong Peng, Hebei Li, Peixi Wu, Yueyi Zhang, Xiaoyan Sun, and Feng Wu",
    "org": "University of Science and Technology of China",
    "date": "2024-10-17",
    "arxiv": "https://arxiv.org/abs/2410.13842",
    "github": "https://github.com/Peterande/D-FINE",
    "docs": "https://github.com/Peterande/D-FINE/blob/master/README.md",
    "official": false,
    "latest": false,
    "show_graph": false,
    "show_card": false,
    "tasks": ["Detect"],
    "performance": {
      "n": {
        "size": 640,
        "map": 42.8,
        "cpu": "",
        "t4": 2.28,
        "params": 4,
        "flops": 7,
        "file_size": "",
        "model_full_name": "D-FINE-N"
      },
      "s": {
        "size": 640,
        "map": 48.5,
        "cpu": "",
        "t4": 4.19,
        "params": 10,
        "flops": 25,
        "file_size": "",
        "model_full_name": "D-FINE-S"
      },
      "m": {
        "size": 640,
        "map": 52.3,
        "cpu": "",
        "t4": 6.85,
        "params": 19,
        "flops": 57,
        "file_size": "",
        "model_full_name": "D-FINE-M"
      },
      "l": {
        "size": 640,
        "map": 54.0,
        "cpu": "",
        "t4": 9.5,
        "params": 31,
        "flops": 91,
        "file_size": "",
        "model_full_name": "D-FINE-L"
      },
      "x": {
        "size": 640,
        "map": 55.8,
        "cpu": "",
        "t4": 15.04,
        "params": 62,
        "flops": 202,
        "file_size": "",
        "model_full_name": "D-FINE-X"
      }
    }
  },
  "YOLO-World": {
    "author": "Tianheng Cheng, Lin Song, Yixiao Ge, Wenyu Liu, Xinggang Wang, and Ying Shan",
    "org": "Tencent AILab Computer Vision Center",
    "short_description": "YOLO-World is a real-time, open-vocabulary extension of the YOLO series that combines vision-language modeling through a Re-parameterizable Vision-Language Path Aggregation Network (RepVL-PAN) and region-text contrastive pre-training to enable zero-shot detection",
    "date": "2024-01-30",
    "arxiv": "https://arxiv.org/abs/2401.17270",
    "github": "https://github.com/AILab-CVC/YOLO-World",
    "docs": "https://docs.ultralytics.com/models/yolo-world/",
    "official": false,
    "latest": false,
    "show_graph": false,
    "show_card": true,
    "weightBase": "yolov8",
    "tasks": ["Open Vocabulary", "Detect"],
    "performance": {
      "s": {
        "size": 640,
        "map": 46.1,
        "cpu": "",
        "t4": 3.46,
        "params": 12.7,
        "flops": 51.0,
        "file_size": "24.7",
        "model_full_name": "YOLO-World-S"
      },
      "m": {
        "size": 640,
        "map": 51.0,
        "cpu": "",
        "t4": 7.26,
        "params": 28.4,
        "flops": 110.5,
        "file_size": "54.6",
        "model_full_name": "YOLO-World-M"
      },
      "l": {
        "size": 640,
        "map": 53.9,
        "cpu": "",
        "t4": 11.0,
        "params": 46.8,
        "flops": 204.5,
        "file_size": "89.9",
        "model_full_name": "YOLO-World-L"
      },
      "x": {
        "size": 640,
        "map": 54.7,
        "cpu": "",
        "t4": 17.24,
        "params": 72.88,
        "flops": 309.3,
        "file_size": "140",
        "model_full_name": "YOLO-World-X"
      }
    }
  },
  "RTMDet": {
    "author": "Chengqi Lyu, Wenwei Zhang, Haian Huang, Yue Zhou, Yudong Wang, Yanyi Liu, Shilong Zhang, and Kai Chen",
    "org": "OpenMMLab",
    "short_description": "RTMDet introduces an efficient real-time object detector that surpasses YOLO-series models by using large-kernel depth-wise convolutions in both backbone and neck, along with soft-label dynamic assignment and optimized training strategies.",
    "date": "2022-12-14",
    "arxiv": "https://arxiv.org/abs/2212.07784",
    "github": "https://github.com/open-mmlab/mmdetection/tree/3.x/configs/rtmdet",
    "docs": "https://github.com/open-mmlab/mmdetection/tree/3.x/configs/rtmdet#readme",
    "official": false,
    "latest": false,
    "show_graph": false,
    "show_card": false,
    "tasks": ["Detect"],
    "performance": {
      "t": {
        "size": 640,
        "map": 41.1,
        "cpu": "",
        "t4": 2.54,
        "params": 4.8,
        "flops": 8.1,
        "file_size": "",
        "model_full_name": "RTMDet-T"
      },
      "s": {
        "size": 640,
        "map": 44.6,
        "cpu": "",
        "t4": 3.18,
        "params": 8.89,
        "flops": 14.8,
        "file_size": "",
        "model_full_name": "RTMDet-S"
      },
      "m": {
        "size": 640,
        "map": 49.4,
        "cpu": "",
        "t4": 6.82,
        "params": 24.71,
        "flops": 39.27,
        "file_size": "",
        "model_full_name": "RTMDet-M"
      },
      "l": {
        "size": 640,
        "map": 51.5,
        "cpu": "",
        "t4": 11.06,
        "params": 52.3,
        "flops": 80.23,
        "file_size": "",
        "model_full_name": "RTMDet-L"
      },
      "x": {
        "size": 640,
        "map": 52.8,
        "cpu": "",
        "t4": 19.66,
        "params": 94.86,
        "flops": 141.67,
        "file_size": "",
        "model_full_name": "RTMDet-X"
      }
    }
  },
  "YOLO-NAS": {
    "author": "Shay Aharon, Louis-Dupont, Ofri Masad, Kate Yurkova, Lotem Fridman, Lkdci, Eugene Khvedchenya, Ran Rubin, Natan Bagrov, Borys Tymchenko, Tomer Keren, Alexander Zhilko, and Eran-Deci",
    "org": "Deci AI (acquired by NVIDIA)",
    "short_description": "YOLO-NAS is a cutting-edge object detection foundational model developed using advanced Neural Architecture Search (AutoNAC), offering quantization-friendly design and superior latency-accuracy trade offs with INT-8 variants showing minimal drop in precision.",
    "date": "2023-05-03",
    "arxiv": "",
    "github": "https://github.com/Deci-AI/super-gradients/blob/master/YOLONAS.md",
    "docs": "https://docs.ultralytics.com/models/yolo-nas/",
    "official": false,
    "latest": false,
    "show_graph": false,
    "show_card": false,
    "tasks": ["Detect"],
    "performance": {
      "s": {
        "size": 640,
        "map": 47.5,
        "cpu": "",
        "t4": 3.09,
        "params": 12.2,
        "flops": 32.8,
        "file_size": 83.3,
        "model_full_name": "YOLO-NAS S"
      },
      "m": {
        "size": 640,
        "map": 51.6,
        "cpu": "",
        "t4": 6.07,
        "params": 31.9,
        "flops": 88.9,
        "file_size": 249,
        "model_full_name": "YOLO-NAS M"
      },
      "l": {
        "size": 640,
        "map": 52.2,
        "cpu": "",
        "t4": 7.84,
        "params": 42.02,
        "flops": 121.09,
        "file_size": 328,
        "model_full_name": "YOLO-NAS L"
      }
    }
  },
  "FCOS": {
    "author": "Zhi Tian, Chunhua Shen, Hao Chen, and Tong He",
    "org": "The University of Adelaide",
    "short_description": "FCOS is a fully convolutional one-stage object detection framework that eliminates the need for anchor boxes, achieving state-of-the-art performance on COCO while maintaining simplicity and efficiency.",
    "date": "2019-04-02",
    "arxiv": "https://arxiv.org/abs/1904.01355",
    "github": "https://github.com/tianzhi0549/FCOS/",
    "docs": "https://github.com/tianzhi0549/FCOS/?tab=readme-ov-file#installation",
    "official": false,
    "latest": false,
    "show_graph": false,
    "show_card": false,
    "tasks": ["Detect"],
    "performance": {
      "R50": {
        "size": 800,
        "map": 36.6,
        "cpu": "",
        "t4": 15.18,
        "params": 32.3,
        "flops": 250.9,
        "file_size": "",
        "model_full_name": "FCOS-R50"
      },
      "R101": {
        "size": 800,
        "map": 39.1,
        "cpu": "",
        "t4": 18.91,
        "params": 51.28,
        "flops": 346.1,
        "file_size": "",
        "model_full_name": "FCOS-R101"
      }
    }
  },
  "SSD": {
    "author": "Wei Liu, Dragomir Anguelov, Dumitru Erhan, Christian Szegedy, Scott Reed, Cheng-Yang Fu, and Alexander C. Berg",
    "org": "University of North Carolina at Chapel Hill",
    "short_description": "SSD (Single Shot MultiBox Detector) is a single-stage object detection model that uses a series of convolutional layers to predict bounding boxes and class scores directly from feature maps, achieving high accuracy and speed.",
    "date": "2015-12-08",
    "arxiv": "https://arxiv.org/abs/1512.02325",
    "github": "https://github.com/weiliu89/caffe/tree/ssd",
    "docs": "https://github.com/weiliu89/caffe/tree/ssd?tab=readme-ov-file#installation",
    "official": false,
    "latest": false,
    "show_graph": false,
    "show_card": false,
    "tasks": ["Detect"],
    "performance": {
      "300": {
        "size": 300,
        "map": 25.5,
        "cpu": "",
        "t4": 3.97,
        "params": 34.3,
        "flops": 68.7,
        "file_size": "",
        "model_full_name": "SSD300"
      },
      "512": {
        "size": 512,
        "map": 29.5,
        "cpu": "",
        "t4": 8.96,
        "params": 36.0,
        "flops": 197.3,
        "file_size": "",
        "model_full_name": "SSD512"
      }
    }
  },
  "RTDETRv3": {
    "author": "Shuo Wang, Chunlong Xia, Feng Lv and Yifeng Shi",
    "org": "Baidu",
    "short_description": "RT-DETRv3 enhances the RT-DETR real-time transformer detector by introducing hierarchical dense positive supervision through a CNN-based auxiliary branch, self-attention perturbation, and a shared-weight decoder branch all training-only modules that significantly boost training effectiveness and overall performance.",
    "date": "2024-09-13",
    "arxiv": "https://arxiv.org/abs/2409.08475",
    "github": "https://github.com/clxia12/RT-DETRv3",
    "docs": "https://github.com/clxia12/RT-DETRv3/blob/main/README.md",
    "official": false,
    "latest": false,
    "show_graph": false,
    "show_card": true,
    "weightBase": "rtdetr-",
    "tasks": ["Detect"],
    "performance": {
      "s": {
        "size": 640,
        "map": 48.1,
        "cpu": "",
        "t4": 5.03,
        "params": 20,
        "flops": 60,
        "file_size": "",
        "model_full_name": "RTDETRv3-S"
      },
      "m": {
        "size": 640,
        "map": 49.9,
        "cpu": "",
        "t4": 7.51,
        "params": 36,
        "flops": 100,
        "file_size": "",
        "model_full_name": "RTDETRv3-M"
      },
      "l": {
        "size": 640,
        "map": 53.4,
        "cpu": "",
        "t4": 9.76,
        "params": 42,
        "flops": 136,
        "file_size": 63.4,
        "model_full_name": "RTDETRv3-L"
      },
      "x": {
        "size": 640,
        "map": 54.6,
        "cpu": "",
        "t4": 15.03,
        "params": 76,
        "flops": 259,
        "file_size": 129,
        "model_full_name": "RTDETRv3-X"
      }
    }
  },
  "LWDETR": {
    "author": "Qiang Chen, Xiangbo Su, Xinyu Zhang, Jian Wang, Jiahui Chen, Yunpeng Shen, Chuchu Han, Ziliang Chen, Weixiang Xu, Fanrong Li, Shan Zhang, Kun Yao, Errui Ding, Gang Zhang, and Jingdong Wang",
    "org": "Baidu",
    "short_description": "LW-DETR is a lightweight detection transformer that replaces the YOLO framework with a plain ViT encoder, convolutional projector, and shallow DETR decoder, using multi-level feature aggregation and interleaved window/global attention to deliver superior real-time object detection performance.",
    "date": "2024-06-05",
    "arxiv": "https://arxiv.org/abs/2406.03459",
    "github": "https://github.com/Atten4Vis/LW-DETR",
    "docs": "https://github.com/Atten4Vis/LW-DETR/blob/main/README.md",
    "official": false,
    "latest": false,
    "show_graph": false,
    "show_card": false,
    "tasks": ["Detect"],
    "performance": {
      "tiny": {
        "size": 640,
        "map": 42.6,
        "cpu": "",
        "t4": 2.56,
        "params": 12.1,
        "flops": 11.2,
        "file_size": "",
        "model_full_name": "LWDETR-tiny"
      },
      "small": {
        "size": 640,
        "map": 48.0,
        "cpu": "",
        "t4": 3.72,
        "params": 14.6,
        "flops": 16.6,
        "file_size": "",
        "model_full_name": "LWDETR-small"
      },
      "medium": {
        "size": 640,
        "map": 52.5,
        "cpu": "",
        "t4": 6.59,
        "params": 28.2,
        "flops": 42.8,
        "file_size": "",
        "model_full_name": "LWDETR-medium"
      },
      "large": {
        "size": 640,
        "map": 56.1,
        "cpu": "",
        "t4": 10.57,
        "params": 46.8,
        "flops": 71.6,
        "file_size": "",
        "model_full_name": "LWDETR-large"
      },
      "xlarge": {
        "size": 640,
        "map": 58.3,
        "cpu": "",
        "t4": 22.29,
        "params": 118.0,
        "flops": 174.1,
        "file_size": "",
        "model_full_name": "LWDETR-xlarge"
      }
    }
  }
}
