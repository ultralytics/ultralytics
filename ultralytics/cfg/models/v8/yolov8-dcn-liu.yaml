# YOLOv8 with DCN v2 - Liu et al. Configuration (BACKBONE-ONLY DCN)
# Reference: Liu et al. "YOLOv8 with Deformable Convolution for Improved Object Detection"
#
# ┌──────────────────────────────────────────────────────────────────────────┐
# │ KEY DIFFERENCE vs yolov8-dcn.yaml:                                       │
# │ ✓ This config: DCN ONLY in BACKBONE (P3/P4)                             │
# │ ✓ yolov8-dcn: DCN in BACKBONE (P3/P4) + NECK FPN (P4 fusion layer)      │
# │                                                                           │
# │ DCN Layers:                                                               │
# │ - yolov8-dcn-liu.yaml: 2 DCN layers (backbone only) - SIMPLER            │
# │ - yolov8-dcn.yaml:     3 DCN layers (backbone + neck) - MORE ADAPTIVE    │
# │                                                                           │
# │ When to use THIS config (yolov8-dcn-liu):                                │
# │ ✓ Simpler baseline experiment                                            │
# │ ✓ Lower computational cost (fewer DCN layers)                            │
# │ ✓ Following Liu et al. paper exactly                                     │
# │ ✓ Backbone feature extraction is the priority                            │
# │                                                                           │
# │ When to use yolov8-dcn.yaml instead:                                     │
# │ ✓ Maximum performance needed (+1-3% more mAP than Liu)                   │
# │ ✓ Complex multi-scale fusion scenarios                                   │
# │ ✓ Can afford extra computation for neck DCN                              │
# └──────────────────────────────────────────────────────────────────────────┘
#
# Architecture Design Rationale (Liu et al.):
# 1. Early layers (P1/P2): Standard Conv - features too simple, DCN adds overhead without benefit
# 2. Middle layers (P3/P4): DCN v2 - critical for geometric adaptation (Zhu et al. 2019, Sec. 4.2)
# 3. Deep layers (P5): Standard Conv - large receptive field already captures context
# 4. NECK (FPN/PAN): ALL Standard Conv - Liu et al. uses backbone DCN only
#
# DCN Placement Strategy (Liu et al.):
# - Backbone P3/8: DCN v2 handles small-medium objects (cars, motorcycles) - 6 repeats
# - Backbone P4/16: DCN v2 handles medium-large objects (buses, trucks) - 6 repeats
# - Neck: ALL standard convolutions (difference from yolov8-dcn.yaml!)
# - Focus: Backbone feature extraction where geometric variation is highest
#
# Expected Performance (Liu et al. experiments):
# - mAP improvement: +4-8% over baseline YOLOv8n
# - Best for: Multi-scale object detection with geometric variation
# - Note: yolov8-dcn.yaml may achieve +1-3% higher due to neck DCN
#
# References:
# - Zhu et al. "Deformable ConvNets v2: More Deformable, Better Results" CVPR 2019
# - Liu et al. YOLOv8-DCN configuration for vehicle detection

nc: 6
depth_multiple: 0.33
width_multiple: 0.25

backbone:
  # [from, repeats, module, args]
  - [-1, 1, Conv, [64, 3, 2]]            # 0-P1/2 - Standard: low-level edges/textures
  - [-1, 1, Conv, [128, 3, 2]]           # 1-P2/4 - Standard: simple patterns
  - [-1, 3, C2f, [128, True]]            # 2 - Standard: feature aggregation
  - [-1, 1, Conv, [256, 3, 2]]           # 3-P3/8 - Standard: downsampling
  - [-1, 6, DeformC2f, [256, True]]      # 4 - DCN v2! Small-medium objects (Liu et al.)
  - [-1, 1, Conv, [512, 3, 2]]           # 5-P4/16 - Standard: downsampling
  - [-1, 6, DeformC2f, [512, True]]      # 6 - DCN v2! Medium-large objects (Liu et al.)
  - [-1, 1, Conv, [1024, 3, 2]]          # 7-P5/32 - Standard: downsampling
  - [-1, 3, C2f, [1024, True]]           # 8 - Standard: large receptive field sufficient
  - [-1, 1, SPPF, [1024, 5]]             # 9 - Spatial Pyramid Pooling

head:
  # FPN (Feature Pyramid Network) - Top-down pathway
  # Design: Standard Conv (Liu et al.) - neck uses standard convolutions
  # Rationale: DCN in backbone already provides adaptive features
  - [-1, 1, nn.Upsample, [None, 2, "nearest"]]  # 10 - Upsample P5→P4
  - [[-1, 6], 1, Concat, [1]]                   # 11 - Concat P4 (from DCN backbone)
  - [-1, 3, C2f, [512]]                         # 12 - Standard: fuse multi-scale features

  - [-1, 1, nn.Upsample, [None, 2, "nearest"]]  # 13 - Upsample P4→P3
  - [[-1, 4], 1, Concat, [1]]                   # 14 - Concat P3 (from DCN backbone)
  - [-1, 3, C2f, [256]]                         # 15 (P3/8-small) - Small object detection

  # PAN (Path Aggregation Network) - Bottom-up pathway
  - [-1, 1, Conv, [256, 3, 2]]                  # 16 - Downsample P3→P4
  - [[-1, 12], 1, Concat, [1]]                  # 17 - Concat P4
  - [-1, 3, C2f, [512]]                         # 18 (P4/16-medium) - Medium object detection

  - [-1, 1, Conv, [512, 3, 2]]                  # 19 - Downsample P4→P5
  - [[-1, 9], 1, Concat, [1]]                   # 20 - Concat P5
  - [-1, 3, C2f, [1024]]                        # 21 (P5/32-large) - Large object detection

  # Detection Head
  - [[15, 18, 21], 1, Detect, [nc]]             # 22 - Multi-scale detection (P3, P4, P5)
