# Ultralytics ðŸš€ AGPL-3.0 License - https://ultralytics.com/license

# Stereo 3D Detection Full Configuration
# Based on Stereo CenterNet paper implementation gap analysis
#
# This configuration enables all advanced features from the paper:
# - GAP-001: Geometric construction solver (Gauss-Newton)
# - GAP-002: Dense photometric alignment (NCC/SAD)
# - GAP-003: Heatmap NMS (3Ã—3 max pooling)
# - GAP-004: Perspective keypoint selection
# - GAP-005: DLA-34 backbone support
# - GAP-006: Occlusion classification
# - GAP-007: Uncertainty-weighted loss

# =============================================================================
# Model Architecture (GAP-005 / T035)
# =============================================================================

# Task identification
# This flag identifies this as a stereo 3D detection model
stereo: true

# Input channels (6 = left RGB + right RGB for stereo)
input_channels: 6

# Parameters
# Number of classes (KITTI: Car, Pedestrian, Cyclist)
nc: 3

# Backbone selection - controls the feature extraction network
# The backbone is shared between left and right images (weight sharing - T034)
#
# Available options:
#   - "resnet18": ResNet-18 backbone (512 output channels)
#     - Best for: Real-time applications requiring â‰¥30 FPS
#     - Expected AP3D: ~32% (Moderate, KITTI)
#     - Dependencies: torchvision (included)
#
#   - "resnet50": ResNet-50 backbone (2048 output channels)  
#     - Best for: Higher accuracy when speed is less critical
#     - Expected AP3D: ~35% (Moderate, KITTI)
#     - Dependencies: torchvision (included)
#
#   - "dla34": DLA-34 with Deep Layer Aggregation (512 output channels)
#     - Best for: Maximum accuracy (+8.73% AP3D vs ResNet-18)
#     - Expected AP3D: ~41% (Moderate, KITTI) 
#     - Inference speed: ~20+ FPS
#     - Dependencies: timm>=0.9.0 (install with: pip install timm)
#
# YOLO11-style backbone (copied from yolo11-obb.yaml:18-30)
# Format: [from, repeats, module, args]
backbone:
  - [-1, 1, StereoConv, [64, 3, 2]] # 0-P1/2: 6â†’64 channels (was Conv in yolo11-obb.yaml)
  - [-1, 1, Conv, [128, 3, 2]] # 1-P2/4
  - [-1, 2, C3k2, [256, False, 0.25]]
  - [-1, 1, Conv, [256, 3, 2]] # 3-P3/8
  - [-1, 2, C3k2, [512, False, 0.25]]
  - [-1, 1, Conv, [512, 3, 2]] # 5-P4/16
  - [-1, 2, C3k2, [512, True]]
  - [-1, 1, Conv, [1024, 3, 2]] # 7-P5/32
  - [-1, 2, C3k2, [1024, True]]
  - [-1, 1, SPPF, [1024, 5]] # 9
  - [-1, 2, C2PSA, [1024]] # 10

# Head structure for stereo 3D detection
# PAN neck top-down path (like yolo11-obb.yaml:34-40)
head:
  # Top-down path: Start from backbone output (layer 10) and upsample to P4
  - [-1, 1, nn.Upsample, [None, 2, "nearest"]]
  - [[-1, 6], 1, Concat, [1]] # cat backbone P4 (layer 6 = C3k2 after P4/16)
  - [-1, 2, C3k2, [512, False]] # 13

  # Continue top-down: Upsample to P3
  - [-1, 1, nn.Upsample, [None, 2, "nearest"]]
  - [[-1, 4], 1, Concat, [1]] # cat backbone P3 (layer 4 = C3k2 after P3/8)
  - [-1, 2, C3k2, [256, False]] # 16 (P3/8-small)

  # Bottom-up path (T008 - PAN neck bottom-up, like yolo11-obb.yaml:42-48)
  - [-1, 1, Conv, [256, 3, 2]]
  - [[-1, 13], 1, Concat, [1]] # cat head P4 (references layer 13 from top-down path)
  - [-1, 2, C3k2, [512, False]] # 19 (P4/16-medium)

  - [-1, 1, Conv, [512, 3, 2]]
  - [[-1, 10], 1, Concat, [1]] # cat head P5 (references layer 10 from backbone)
  - [-1, 2, C3k2, [1024, True]] # 22 (P5/32-large)

  # Detection head (T009 - Replace Detect with StereoCenterNetHead, single-scale P3)
  - [[16], 1, StereoCenterNetHead, [nc, 256]] # Single-scale detection at P3/8

# Mean dimensions per class [L, W, H] in meters (for dimension regression)
mean_dims:
  Car: [3.88, 1.63, 1.53]
  Pedestrian: [0.88, 0.60, 1.73]
  Cyclist: [1.72, 0.60, 1.77]

# =============================================================================
# Inference Settings
# =============================================================================

inference:
  # Confidence threshold for detection filtering
  conf_threshold: 0.3
  
  # Maximum number of detections to return per image
  top_k: 100
  
  # Heatmap NMS (GAP-003): Apply 3Ã—3 max pooling to suppress non-maxima
  # Paper: Section 3.1 "For inference, use the 3Ã—3 max pooling operation instead of NMS"
  use_nms: true
  nms_kernel: 3

# =============================================================================
# Geometric Construction (GAP-001)
# =============================================================================

# Solve for 3D box parameters (x, y, z, Î¸) using 7 geometric constraint equations
# Paper: Section 3.2, Equation 9 - Gauss-Newton optimization
geometric_construction:
  # Enable geometric construction solver
  enabled: true
  
  # Gauss-Newton solver parameters
  max_iterations: 10
  tolerance: 1.0e-6
  
  # Levenberg-Marquardt damping factor for numerical stability
  damping: 1.0e-3
  
  # Fallback to simple triangulation if solver fails to converge
  fallback_on_failure: true

# =============================================================================
# Dense Photometric Alignment (GAP-002)
# =============================================================================

# Refine depth estimates using photometric matching between stereo images
# Paper: Section 3.2 "Dense Alignment"
dense_alignment:
  # Enable dense alignment for depth refinement
  enabled: true
  
  # Matching method: "ncc" (Normalized Cross-Correlation) or "sad" (Sum of Absolute Differences)
  # NCC is more robust to lighting variations, SAD is faster
  method: ncc
  
  # Depth search range (meters) around initial estimate
  depth_search_range: 2.0
  
  # Number of depth hypotheses to evaluate
  depth_steps: 32
  
  # Patch size for photometric matching (pixels)
  patch_size: 7

# =============================================================================
# Occlusion Handling (GAP-006)
# =============================================================================

# Classify objects as occluded/unoccluded using depth-line algorithm
# Paper: Algorithm 1 "3D Object Classification Strategy"
occlusion:
  # Enable occlusion classification
  enabled: true
  
  # Skip dense alignment for heavily occluded objects (improves robustness)
  skip_dense_for_occluded: true

# =============================================================================
# Training Settings
# =============================================================================

# Optimizer selection: 'auto' (automatic), 'SGD', 'Adam', 'AdamW', 'NAdam', 'RAdam', 'RMSProp'
# 'auto' selects AdamW for stereo3ddet based on model configuration
optimizer: auto

# Validation during training: enable to monitor AP3D metrics during training
val: true

training:
  # Uncertainty-weighted multi-task loss (GAP-007)
  # Enables automatic balancing of loss components using learned uncertainty parameters
  # Paper: Kendall et al. "Multi-Task Learning Using Uncertainty to Weigh Losses"
  use_uncertainty_weighting: false
  
  # Individual loss weights (used when uncertainty_weighting is disabled)
  loss_weights:
    heatmap: 1.0
    offset: 1.0
    bbox_size: 0.1
    lr_distance: 1.0
    right_width: 0.1
    dimensions: 0.1
    orientation: 1.0
    vertices: 1.0
    vertex_offset: 1.0
    vertex_dist: 0.1

# =============================================================================
# Performance Targets (from paper)
# =============================================================================

# Reference metrics on KITTI validation set:
#
# | Configuration          | AP3D@0.7 (Moderate) | Inference Speed |
# |------------------------|---------------------|-----------------|
# | ResNet-18 (geo only)   | â‰¥30%                | â‰¥30 FPS         |
# | ResNet-18 (full)       | â‰¥32.71%             | â‰¥30 FPS         |
# | DLA-34 (full)          | â‰¥41.44%             | â‰¥20 FPS         |
#
# Success Criteria:
# - SC-001: AP3D â‰¥30% with geometric construction only
# - SC-002: AP3D â‰¥32% with full pipeline
# - SC-003: AP3D â‰¥40% with DLA-34 backbone
# - SC-004: â‰¥30 FPS inference (ResNet-18)
# - SC-005: â‰¥20 FPS inference (DLA-34)
# - SC-006: No duplicate detections (via NMS)
# - SC-007: â‰¥95% geometric solver convergence rate
# - SC-008: â‰¥85% occlusion classification accuracy

