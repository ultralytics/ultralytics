{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c32f7e63-805a-486c-8c20-6de7b286bf73",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "272da4da-3e4b-47be-9061-3ed392a6be7b",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# TinyPersons dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2e555652-71ce-463b-bb47-12fa41350a58",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#YOLO FORMAT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "22c102a7-7848-42f1-906e-35e86b0c36fa",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Annotations /Users/inaki-eab/Desktop/DETECTOR_DATASETS/TinyPersonsCOCO/test/_ann\n"
     ]
    }
   ],
   "source": [
    "from ultralytics.data.converter import convert_coco\n",
    "convert_coco('/Users/inaki-eab/Desktop/DETECTOR_DATASETS/TinyPersonsCOCO/test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "01604b48-c23a-4101-ba55-952862f9d428",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# new empty structure\n",
    "root_path = '/Users/inaki-eab/Desktop/DETECTOR_DATASETS'\n",
    "#root_path = '/data-fast/127-data2/ierregue/datasets'\n",
    "\n",
    "dataset_name = 'custom_tiny'\n",
    "\n",
    "new_dataset_root = os.path.join(root_path, dataset_name)\n",
    "\n",
    "# Create folder structure\n",
    "if not os.path.isdir(new_dataset_root):\n",
    "    os.makedirs(new_dataset_root)\n",
    "    os.makedirs(os.path.join(new_dataset_root, 'labels','train'))\n",
    "    os.makedirs(os.path.join(new_dataset_root, 'labels','test'))\n",
    "    os.makedirs(os.path.join(new_dataset_root, 'labels','val'))\n",
    "    os.makedirs(os.path.join(new_dataset_root, 'images','train'))\n",
    "    os.makedirs(os.path.join(new_dataset_root, 'images','test'))\n",
    "    os.makedirs(os.path.join(new_dataset_root, 'images','val'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f9e3d088-a79d-4b0f-b43b-d4bc95e5c570",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "wanted_indices = [\n",
    "    0, #aeroplane\n",
    "    1, #boat\n",
    "    2, #car\n",
    "    3, #person\n",
    "    4, #truck\n",
    "    5, #uav\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "728baadb-fe58-4859-ac0e-77438e6315ff",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def clean_map_file(file):\n",
    "# Mapping should be performed only once\n",
    "    \n",
    "    class_index_map = {\n",
    "        5:3, # drone/uav\n",
    "        0:4, # aeroplane\n",
    "        1:5, # boat\n",
    "        2:1, # car\n",
    "        3:0, # person\n",
    "        4:2, # truck\n",
    "    }\n",
    "    \n",
    "    with open(file, 'r+') as fp:\n",
    "        # read an store all lines into list\n",
    "        lines = fp.readlines()\n",
    "        # move file pointer to the beginning of a file\n",
    "        fp.seek(0)\n",
    "        # truncate the file\n",
    "        fp.truncate()\n",
    "    \n",
    "        # start writing lines\n",
    "        # iterate line and line number\n",
    "        for number, line in enumerate(lines):\n",
    "            # Only write rows of interested instances\n",
    "            old_class_id = int(line.split()[0])\n",
    "            if old_class_id in wanted_indices:\n",
    "                # map old class indices to new ones\n",
    "                new_class_id = class_index_map[old_class_id]\n",
    "                new_line_splitted = line.split()\n",
    "                new_line_splitted[0] = str(new_class_id)\n",
    "                new_line = ' '.join(new_line_splitted)\n",
    "                fp.write(new_line+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "525e4260-ed5e-40c5-b86c-c55f9aa18391",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def move_desired_files(\n",
    "    original_dataset_root, #../datasets/old_dataset\n",
    "    target_dataset_root, # ../datasets/new_dataset\n",
    "    original_dataset_slice, # liketrain,test,val\n",
    "    target_dataset_slice, # train,test,val\n",
    "    wanted_indices # list of desired indices\n",
    "):\n",
    "    # Empty list to store the selected files containing at list one of the desired objects\n",
    "    selected_images = []\n",
    "    \n",
    "    \n",
    "    original_labels_dir = os.path.join(original_dataset_root, 'labels', original_dataset_slice)\n",
    "    original_images_dir = os.path.join(original_dataset_root, 'images', original_dataset_slice)\n",
    "\n",
    "    # Iterate over all files in the original dataset labels folder\n",
    "    for filename in os.listdir(original_labels_dir):\n",
    "        if filename.endswith('.txt'):\n",
    "            # Read file\n",
    "            with open(os.path.join(original_labels_dir, filename), \"r\") as f:\n",
    "                # Empty list to store objects/instances present in image\n",
    "                indices_in_file = []\n",
    "                # Iterate over instances in image and get present class ids\n",
    "                for line in f:\n",
    "                    indices_in_file.append(int(line.split()[0]))\n",
    "                # If any present class ids is a class id of interest, get its filename\n",
    "                if any((True for x in indices_in_file if x in wanted_indices)):\n",
    "                    # Get only name, no '.txt' extension\n",
    "                    selected_images.append(os.path.splitext(filename)[0])\n",
    "                    # Copy *.txt folder\n",
    "                    shutil.copy(os.path.join(original_labels_dir, filename), os.path.join(target_dataset_root, 'labels', target_dataset_slice))\n",
    "                    # Copy *jpg image\n",
    "                    img_path = os.path.join(original_images_dir, os.path.splitext(filename)[0]+'.jpg')\n",
    "                    shutil.copy(img_path, os.path.join(target_dataset_root, 'images', target_dataset_slice))\n",
    "\n",
    "                    # Map old index to new one and delete unwanted instances\n",
    "                    clean_map_file(os.path.join(target_dataset_root, 'labels', target_dataset_slice, filename))\n",
    "                    \n",
    "    return selected_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "79baf99f-ff27-4b80-9031-21b297a81bc6",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "original_dataset_path = 'TinyPersonsCOCO'\n",
    "original_dataset_root = os.path.join(root_path, original_dataset_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ed1df2c8-34b6-4d35-92a5-d847b212e18d",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "val_indices = move_desired_files(original_dataset_root, \n",
    "                                   new_dataset_root, \n",
    "                                   'val', \n",
    "                                   'val', \n",
    "                                   wanted_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c4da5247-54cf-45f1-b307-2f34b468a881",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "train_indices = move_desired_files(original_dataset_root, \n",
    "                                   new_dataset_root, \n",
    "                                   'train', \n",
    "                                   'train', \n",
    "                                   wanted_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dd2fff73-f83d-4e4a-b86e-65adde00124a",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Rename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "baa022c0-5133-4196-a47b-b84b201709d2",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "old_len_img_train = len(os.listdir(os.path.join(new_dataset_root,'images','train')))\n",
    "old_len_img_val = len(os.listdir(os.path.join(new_dataset_root,'images','val')))\n",
    "old_len_txt_val = len(os.listdir(os.path.join(new_dataset_root,'labels','val')))\n",
    "old_len_txt_train = len(os.listdir(os.path.join(new_dataset_root,'labels','train')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5a089e90-2182-4aea-9b17-c853a32cc231",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def rename_dir(dir, shift=1):\n",
    "    files = [f for f in os.listdir(dir)]\n",
    "    #files.sort(key=lambda x: int(re.match(r'\\d+', x).group()))\n",
    "    files.sort()\n",
    "    \n",
    "    for idx, old_filename in enumerate(files):\n",
    "        extension = os.path.splitext(old_filename)[1]\n",
    "        new_filename = f'{idx+shift}{extension}'\n",
    "        old_path = os.path.join(dir, old_filename)\n",
    "        new_path = os.path.join(dir, new_filename)\n",
    "        os.rename(old_path, new_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6366f97f-cd3f-40a8-a9ce-1bcf109e0538",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "rename_dir(os.path.join(new_dataset_root,'images','train'), shift=1+53518)\n",
    "rename_dir(os.path.join(new_dataset_root,'images','val'), shift=1+9333)\n",
    "rename_dir(os.path.join(new_dataset_root,'labels','train'), shift=1+53518)\n",
    "rename_dir(os.path.join(new_dataset_root,'labels','val'), shift=1+9333)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "91444d9b-7a21-480f-a601-004053f39b1e",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# CHECK THAT WE HAVE THE SAME NUMBER OF FILES\n",
    "assert old_len_img_train == len(os.listdir(os.path.join(new_dataset_root,'images','train')))\n",
    "assert old_len_img_val == len(os.listdir(os.path.join(new_dataset_root,'images','val')))\n",
    "assert old_len_txt_val == len(os.listdir(os.path.join(new_dataset_root,'labels','val')))\n",
    "assert old_len_txt_train == len(os.listdir(os.path.join(new_dataset_root,'labels','train')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23c1e2a7-3a21-4081-995e-5fe68f96fe71",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}