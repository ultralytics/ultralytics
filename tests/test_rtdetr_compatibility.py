# Ultralytics ðŸš€ AGPL-3.0 License - https://ultralytics.com/license
"""
Test RT-DETR v1/v2 compatibility and version detection.

This module tests the backward compatibility between RT-DETR v1 and v2 architectures, ensuring that existing v1 weights
continue to work while supporting new v2 features.
"""

import pytest
import torch

from ultralytics import RTDETR
from ultralytics.nn.modules.head import RTDETRDecoder, RTDETRDecoderV2


class TestRTDETRCompatibility:
    """Test RT-DETR v1/v2 compatibility features."""

    def test_v1_decoder_creation(self):
        """Test RT-DETR v1 decoder creation."""
        decoder = RTDETRDecoder(nc=80, ch=(256, 512, 1024))
        assert decoder.nc == 80
        assert decoder.nl == 3

    def test_v2_decoder_creation(self):
        """Test RT-DETR v2 decoder creation."""
        decoder = RTDETRDecoderV2(nc=80, ch=(256, 512, 1024))
        assert decoder.nc == 80
        assert decoder.nl == 3

    def test_v2_decoder_v1_mode(self):
        """Test RT-DETR v2 decoder in v1 compatibility mode."""
        # Create v2 decoder with v1-style ndp parameter
        decoder = RTDETRDecoderV2(nc=80, ch=(256, 512, 1024), ndp=4)
        assert decoder.is_v1_mode
        assert decoder.ndp == [4, 4, 4, 4, 4, 4]  # 6 layers default

    def test_v2_decoder_v2_mode(self):
        """Test RT-DETR v2 decoder in native v2 mode."""
        # Create v2 decoder with v2-style ndp parameter
        decoder = RTDETRDecoderV2(nc=80, ch=(256, 512, 1024), ndp=[4, 4, 4])
        assert not decoder.is_v1_mode
        assert decoder.ndp == [4, 4, 4]

    def test_version_detection(self):
        """Test weight version detection."""
        decoder = RTDETRDecoderV2(nc=80, ch=(256, 512, 1024))

        # Mock v1 state dict with 64-dim sampling_offsets
        v1_state_dict = {
            "decoder.layers.0.sampling_offsets.weight": torch.randn(256, 64),
            "other_param": torch.randn(100, 100),
        }

        # Mock v2 state dict with 192-dim sampling_offsets
        v2_state_dict = {
            "decoder.layers.0.sampling_offsets.weight": torch.randn(256, 192),
            "other_param": torch.randn(100, 100),
        }

        assert decoder._detect_weight_version(v1_state_dict, "") == "v1"
        assert decoder._detect_weight_version(v2_state_dict, "") == "v2"

    def test_v1_to_v2_conversion(self):
        """Test converting v1 weights to v2 format."""
        decoder = RTDETRDecoderV2(nc=80, ch=(256, 512, 1024))

        # Create mock v1 weights
        v1_weights = {
            "decoder.layers.0.sampling_offsets.weight": torch.randn(256, 64),
            "decoder.layers.0.sampling_offsets.bias": torch.randn(64),
            "other_param": torch.randn(100, 100),
        }

        # Convert to v2
        v2_weights = decoder._convert_v1_to_v2_weights(v1_weights, "")

        # Check dimensions
        assert v2_weights["decoder.layers.0.sampling_offsets.weight"].shape == (256, 192)
        assert v2_weights["decoder.layers.0.sampling_offsets.bias"].shape == (192,)
        assert v2_weights["other_param"].shape == (100, 100)  # Unchanged

    def test_v2_to_v1_conversion(self):
        """Test converting v2 weights to v1 format."""
        decoder = RTDETRDecoderV2(nc=80, ch=(256, 512, 1024))

        # Create mock v2 weights
        v2_weights = {
            "decoder.layers.0.sampling_offsets.weight": torch.randn(256, 192),
            "decoder.layers.0.sampling_offsets.bias": torch.randn(192),
            "other_param": torch.randn(100, 100),
        }

        # Convert to v1
        v1_weights = decoder._convert_v2_to_v1_weights(v2_weights, "")

        # Check dimensions
        assert v1_weights["decoder.layers.0.sampling_offsets.weight"].shape == (256, 64)
        assert v1_weights["decoder.layers.0.sampling_offsets.bias"].shape == (64,)
        assert v1_weights["other_param"].shape == (100, 100)  # Unchanged

    def test_model_auto_config_selection(self):
        """Test automatic config selection based on weight version."""
        # This test would need actual weight files, so we'll mock it
        model = RTDETR("rtdetr-l.yaml")  # Direct config loading
        assert model.model is not None

    def test_cross_version_compatibility(self):
        """Test that v1 and v2 models can coexist."""
        # Create v1 model
        model_v1 = RTDETR("rtdetr-l.yaml")

        # Create v2 model
        model_v2 = RTDETR("rtdetrv2-l.yaml")

        # Both should work
        assert model_v1.model is not None
        assert model_v2.model is not None

    def test_forward_compatibility(self):
        """Test forward pass compatibility."""
        # Create test input
        x = [torch.randn(1, 256, 64, 64), torch.randn(1, 512, 32, 32), torch.randn(1, 1024, 16, 16)]

        # Test v1 decoder
        decoder_v1 = RTDETRDecoder(nc=80, ch=(256, 512, 1024))
        decoder_v1.eval()

        # Test v2 decoder in v1 mode
        decoder_v2_v1 = RTDETRDecoderV2(nc=80, ch=(256, 512, 1024), ndp=4)
        decoder_v2_v1.eval()

        # Test v2 decoder in v2 mode
        decoder_v2_v2 = RTDETRDecoderV2(nc=80, ch=(256, 512, 1024), ndp=[4, 4, 4])
        decoder_v2_v2.eval()

        # All should work without errors
        with torch.no_grad():
            try:
                out1 = decoder_v1(x)
                out2 = decoder_v2_v1(x)
                out3 = decoder_v2_v2(x)

                # All outputs should have same structure
                assert len(out1) == len(out2) == len(out3)
                # Check inference output (tensor) shape when not training
                if isinstance(out1, tuple):
                    assert out1[0].shape == out2[0].shape == out3[0].shape  # inference output
                else:
                    assert out1.shape == out2.shape == out3.shape  # direct tensor output

            except Exception as e:
                pytest.fail(f"Forward pass failed: {e}")

    @pytest.mark.slow
    def test_training_compatibility(self):
        """Test training compatibility between versions."""
        # This would test that training works with both v1 and v2
        # Marked as slow since it involves model training
        pass

    def test_export_compatibility(self):
        """Test export compatibility for both versions."""
        # This would test ONNX/TensorRT export compatibility
        pass


if __name__ == "__main__":
    # Run basic tests
    test = TestRTDETRCompatibility()
    test.test_v1_decoder_creation()
    test.test_v2_decoder_creation()
    test.test_v2_decoder_v1_mode()
    test.test_v2_decoder_v2_mode()
    test.test_version_detection()
    test.test_v1_to_v2_conversion()
    test.test_v2_to_v1_conversion()
    test.test_cross_version_compatibility()
    test.test_forward_compatibility()

    print("âœ… All RT-DETR compatibility tests passed!")
